@inproceedings{kim-2014-convolutional,
    title = "Convolutional Neural Networks for Sentence Classification",
    author = "Kim, Yoon",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1181",
    doi = "10.3115/v1/D14-1181",
    pages = "1746--1751",
}
@inproceedings{saravia-etal-2018-carer,
    title = "{CARER}: Contextualized Affect Representations for Emotion Recognition",
    author = "Saravia, Elvis  and
      Liu, Hsien-Chi Toby  and
      Huang, Yen-Hao  and
      Wu, Junlin  and
      Chen, Yi-Shin",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1404",
    doi = "10.18653/v1/D18-1404",
    pages = "3687--3697",
    abstract = "Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.",
}
@article{bojanowski2016enriching,
  title={Enriching Word Vectors with Subword Information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.04606},
  year={2016}
}
@article{joulin2016bag,
  title={Bag of Tricks for Efficient Text Classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.01759},
  year={2016}
}
@misc{kaggledata,
	title={Emotions dataset for NLP},
	author={Govi, Praveen},
	year={2020},
	url="https://www.kaggle.com/praveengovi/emotions-dataset-for-nlp"
}
@misc{mikolov2013distributed,
      title={Distributed Representations of Words and Phrases and their Compositionality}, 
      author={Tomas Mikolov and Ilya Sutskever and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1310.4546},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{xlnet,
  author    = {Zhilin Yang and
               Zihang Dai and
               Yiming Yang and
               Jaime G. Carbonell and
               Ruslan Salakhutdinov and
               Quoc V. Le},
  title     = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  journal   = {CoRR},
  volume    = {abs/1906.08237},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.08237},
  archivePrefix = {arXiv},
  eprint    = {1906.08237},
  timestamp = {Mon, 24 Jun 2019 17:28:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-08237.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{bertclassification,
  author    = {Chi Sun and
               Xipeng Qiu and
               Yige Xu and
               Xuanjing Huang},
  title     = {How to Fine-Tune {BERT} for Text Classification?},
  journal   = {CoRR},
  volume    = {abs/1905.05583},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.05583},
  archivePrefix = {arXiv},
  eprint    = {1905.05583},
  timestamp = {Tue, 21 Jan 2020 13:18:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-05583.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{sentistrength,
author = {Thelwall, Mike and Buckley, Kevan and Paltoglou, Georgios and Cai, Di and Kappas, Arvid},
title = {Sentiment strength detection in short informal text},
journal = {Journal of the American Society for Information Science and Technology},
volume = {61},
number = {12},
pages = {2544-2558},
doi = {10.1002/asi.21416},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.21416},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.21416},
abstract = {Abstract A huge number of informal messages are posted every day in social network sites, blogs, and discussion forums. Emotions seem to be frequently important in these texts for expressing friendship, showing social support or as part of online arguments. Algorithms to identify sentiment and sentiment strength are needed to help understand the role of emotion in this informal communication and also to identify inappropriate or anomalous affective utterances, potentially associated with threatening behavior to the self or others. Nevertheless, existing sentiment detection algorithms tend to be commercially oriented, designed to identify opinions about products rather than user behaviors. This article partly fills this gap with a new algorithm, SentiStrength, to extract sentiment strength from informal English text, using new methods to exploit the de facto grammars and spelling styles of cyberspace. Applied to MySpace comments and with a lookup table of term sentiment strengths optimized by machine learning, SentiStrength is able to predict positive emotion with 60.6\% accuracy and negative emotion with 72.8\% accuracy, both based upon strength scales of 1â€“5. The former, but not the latter, is better than baseline and a wide range of general machine learning approaches.},
year = {2010}
}
@misc{harvardgeneralinquirer,
  title={Harvard General Inquirer},
  year={2020},
  url="http://www.wjh.harvard.edu/~inquirer/homecat.htm"
}
@misc{empathclient,
  title={Empath client},
  year={2020},
  url="https://github.com/Ejhfast/empath-client"
}
@misc{emotiondetection,
  title={Emotion Detection and Recognition from Text Using Deep Learning},
  year={2015},
  author={Chew-Yean},
  url="https://devblogs.microsoft.com/cse/2015/11/29/emotion-detection-and-recognition-from-text-using-deep-learning"
}

@InProceedings{chaffaretal,
author="Chaffar, Soumaya
and Inkpen, Diana",
editor="Butz, Cory
and Lingras, Pawan",
title="Using a Heterogeneous Dataset for Emotion Analysis in Text",
booktitle="Advances in Artificial Intelligence",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="62--67",
abstract="In this paper, we adopt a supervised machine learning approach to recognize six basic emotions (anger, disgust, fear, happiness, sadness and surprise) using a heterogeneous emotion-annotated dataset which combines news headlines, fairy tales and blogs. For this purpose, different features sets, such as bags of words, and N-grams, were used. The Support Vector Machines classifier (SVM) performed significantly better than other classifiers, and it generalized well on unseen examples.",
isbn="978-3-642-21043-3"
}
@inproceedings{johnsonetal,
    title = "Deep Pyramid Convolutional Neural Networks for Text Categorization",
    author = "Johnson, Rie  and
      Zhang, Tong",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P17-1052",
    doi = "10.18653/v1/P17-1052",
    pages = "562--570",
    abstract = "This paper proposes a low-complexity word-level deep convolutional neural network (CNN) architecture for text categorization that can efficiently represent long-range associations in text. In the literature, several deep and complex neural networks have been proposed for this task, assuming availability of relatively large amounts of training data. However, the associated computational complexity increases as the networks go deeper, which poses serious challenges in practical applications. Moreover, it was shown recently that shallow word-level CNNs are more accurate and much faster than the state-of-the-art very deep nets such as character-level CNNs even in the setting of large training data. Motivated by these findings, we carefully studied deepening of word-level CNNs to capture global representations of text, and found a simple network architecture with which the best accuracy can be obtained by increasing the network depth without increasing computational cost by much. We call it deep pyramid CNN. The proposed model with 15 weight layers outperforms the previous best models on six benchmark datasets for sentiment classification and topic categorization.",
}
@inproceedings{dossantosetal,
    title = "Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts",
    author = "dos Santos, C{\'\i}cero  and
      Gatti, Ma{\'\i}ra",
    booktitle = "Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
    month = aug,
    year = "2014",
    address = "Dublin, Ireland",
    publisher = "Dublin City University and Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/C14-1008",
    pages = "69--78",
}
@inproceedings{unsupervisedemotiondetection,
    title = "Unsupervised emotion detection from text using semantic and syntactic relations",
    author = "Agrawal, A. and An, A.",
    booktitle = "Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
    month = December,
    year = "2012",
    publisher = "IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology",
    pages = "346-353",
}

@incollection{jan2020emotion,
  title={Emotion mining using semantic similarity},
  author={Jan, Rafiya and Khan, Afaq Alam},
  booktitle={Natural Language Processing: Concepts, Methodologies, Tools, and Applications},
  pages={1115--1138},
  year={2020},
  publisher={IGI Global}
}
@article{xu2020improving,
  title={Improving BERT Fine-Tuning via Self-Ensemble and Self-Distillation},
  author={Xu, Yige and Qiu, Xipeng and Zhou, Ligao and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2002.10345},
  year={2020}
}
