@inproceedings{kim-2014-convolutional,
    title = "Convolutional Neural Networks for Sentence Classification",
    author = "Kim, Yoon",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1181",
    doi = "10.3115/v1/D14-1181",
    pages = "1746--1751",
}
@inproceedings{saravia-etal-2018-carer,
    title = "{CARER}: Contextualized Affect Representations for Emotion Recognition",
    author = "Saravia, Elvis  and
      Liu, Hsien-Chi Toby  and
      Huang, Yen-Hao  and
      Wu, Junlin  and
      Chen, Yi-Shin",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1404",
    doi = "10.18653/v1/D18-1404",
    pages = "3687--3697",
    abstract = "Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.",
}
@article{bojanowski2016enriching,
  title={Enriching Word Vectors with Subword Information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.04606},
  year={2016}
}
@article{joulin2016bag,
  title={Bag of Tricks for Efficient Text Classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.01759},
  year={2016}
}
@misc{mikolov2013efficient,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{kaggledata,
	title={Emotions dataset for NLP},
	author={Govi, Praveen},
	year={2020},
	url="https://www.kaggle.com/praveengovi/emotions-dataset-for-nlp"
}
@misc{mikolov2013distributed,
      title={Distributed Representations of Words and Phrases and their Compositionality}, 
      author={Tomas Mikolov and Ilya Sutskever and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1310.4546},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{xlnet,
  author    = {Zhilin Yang and
               Zihang Dai and
               Yiming Yang and
               Jaime G. Carbonell and
               Ruslan Salakhutdinov and
               Quoc V. Le},
  title     = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  journal   = {CoRR},
  volume    = {abs/1906.08237},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.08237},
  archivePrefix = {arXiv},
  eprint    = {1906.08237},
  timestamp = {Mon, 24 Jun 2019 17:28:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-08237.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{bertclassification,
  author    = {Chi Sun and
               Xipeng Qiu and
               Yige Xu and
               Xuanjing Huang},
  title     = {How to Fine-Tune {BERT} for Text Classification?},
  journal   = {CoRR},
  volume    = {abs/1905.05583},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.05583},
  archivePrefix = {arXiv},
  eprint    = {1905.05583},
  timestamp = {Tue, 21 Jan 2020 13:18:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-05583.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{sentistrength,
author = {Thelwall, Mike and Buckley, Kevan and Paltoglou, Georgios and Cai, Di and Kappas, Arvid},
title = {Sentiment strength detection in short informal text},
journal = {Journal of the American Society for Information Science and Technology},
volume = {61},
number = {12},
pages = {2544-2558},
doi = {10.1002/asi.21416},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.21416},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.21416},
abstract = {Abstract A huge number of informal messages are posted every day in social network sites, blogs, and discussion forums. Emotions seem to be frequently important in these texts for expressing friendship, showing social support or as part of online arguments. Algorithms to identify sentiment and sentiment strength are needed to help understand the role of emotion in this informal communication and also to identify inappropriate or anomalous affective utterances, potentially associated with threatening behavior to the self or others. Nevertheless, existing sentiment detection algorithms tend to be commercially oriented, designed to identify opinions about products rather than user behaviors. This article partly fills this gap with a new algorithm, SentiStrength, to extract sentiment strength from informal English text, using new methods to exploit the de facto grammars and spelling styles of cyberspace. Applied to MySpace comments and with a lookup table of term sentiment strengths optimized by machine learning, SentiStrength is able to predict positive emotion with 60.6\% accuracy and negative emotion with 72.8\% accuracy, both based upon strength scales of 1–5. The former, but not the latter, is better than baseline and a wide range of general machine learning approaches.},
year = {2010}
}
@misc{harvardgeneralinquirer,
  title={Harvard General Inquirer},
  year={2020},
  url="http://www.wjh.harvard.edu/~inquirer/homecat.htm"
}
@misc{scikit-learn,
  title={Scikit-Learn Library},
  year={2020},
  url="http://scikit-learn.org/stable/index.html"
}
@misc{nltk,
  title={nltk},
  year={2020},
  url="http://www.nltk.org/"
}
@misc{empathclient,
  title={Empath client},
  year={2020},
  url="https://github.com/Ejhfast/empath-client"
}
@misc{emotiondetection,
  title={Emotion Detection and Recognition from Text Using Deep Learning},
  year={2015},
  author={Chew-Yean},
  url="https://devblogs.microsoft.com/cse/2015/11/29/emotion-detection-and-recognition-from-text-using-deep-learning"
}

@InProceedings{chaffaretal,
author="Chaffar, Soumaya
and Inkpen, Diana",
editor="Butz, Cory
and Lingras, Pawan",
title="Using a Heterogeneous Dataset for Emotion Analysis in Text",
booktitle="Advances in Artificial Intelligence",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="62--67",
abstract="In this paper, we adopt a supervised machine learning approach to recognize six basic emotions (anger, disgust, fear, happiness, sadness and surprise) using a heterogeneous emotion-annotated dataset which combines news headlines, fairy tales and blogs. For this purpose, different features sets, such as bags of words, and N-grams, were used. The Support Vector Machines classifier (SVM) performed significantly better than other classifiers, and it generalized well on unseen examples.",
isbn="978-3-642-21043-3"
}
@inproceedings{johnsonetal,
    title = "Deep Pyramid Convolutional Neural Networks for Text Categorization",
    author = "Johnson, Rie  and
      Zhang, Tong",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P17-1052",
    doi = "10.18653/v1/P17-1052",
    pages = "562--570",
    abstract = "This paper proposes a low-complexity word-level deep convolutional neural network (CNN) architecture for text categorization that can efficiently represent long-range associations in text. In the literature, several deep and complex neural networks have been proposed for this task, assuming availability of relatively large amounts of training data. However, the associated computational complexity increases as the networks go deeper, which poses serious challenges in practical applications. Moreover, it was shown recently that shallow word-level CNNs are more accurate and much faster than the state-of-the-art very deep nets such as character-level CNNs even in the setting of large training data. Motivated by these findings, we carefully studied deepening of word-level CNNs to capture global representations of text, and found a simple network architecture with which the best accuracy can be obtained by increasing the network depth without increasing computational cost by much. We call it deep pyramid CNN. The proposed model with 15 weight layers outperforms the previous best models on six benchmark datasets for sentiment classification and topic categorization.",
}
@inproceedings{dossantosetal,
    title = "Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts",
    author = "dos Santos, C{\'\i}cero  and
      Gatti, Ma{\'\i}ra",
    booktitle = "Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
    month = aug,
    year = "2014",
    address = "Dublin, Ireland",
    publisher = "Dublin City University and Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/C14-1008",
    pages = "69--78",
}
@inproceedings{unsupervisedemotiondetection,
    title = "Unsupervised emotion detection from text using semantic and syntactic relations",
    author = "Agrawal, A. and An, A.",
    booktitle = "Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
    month = "December",
    year = "2012",
    publisher = "IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology",
    pages = "346-353",
}

@incollection{jan2020emotion,
  title={Emotion mining using semantic similarity},
  author={Jan, Rafiya and Khan, Afaq Alam},
  booktitle={Natural Language Processing: Concepts, Methodologies, Tools, and Applications},
  pages={1115--1138},
  year={2020},
  publisher={IGI Global}
}
@article{xu2020improving,
  title={Improving BERT Fine-Tuning via Self-Ensemble and Self-Distillation},
  author={Xu, Yige and Qiu, Xipeng and Zhou, Ligao and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2002.10345},
  year={2020}
}
@article{adadelta,
  author    = {Matthew D. Zeiler},
  title     = {{ADADELTA:} An Adaptive Learning Rate Method},
  journal   = {CoRR},
  volume    = {abs/1212.5701},
  year      = {2012},
  url       = {http://arxiv.org/abs/1212.5701},
  archivePrefix = {arXiv},
  eprint    = {1212.5701},
  timestamp = {Mon, 13 Aug 2018 16:45:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1212-5701.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{luhn,
author = {Luhn, H. P.},
title = {A Statistical Approach to Mechanized Encoding and Searching of Literary Information},
year = {1957},
issue_date = {October 1957},
publisher = {IBM Corp.},
address = {USA},
volume = {1},
number = {4},
issn = {0018-8646},
url = "https://doi.org/10.1147/rd.14.0309",
doi = {10.1147/rd.14.0309},
abstract = {Written communication of ideas is carried out on the basis of statistical probability in that a writer chooses that level of subject specificity and that combination of words which he feels will convey the most meaning. Since this process varies among individuals and since similar ideas are therefore relayed at different levels of specificity and by means of different words, the problem of literature searching by machines still presents major difficulties. A statistical approach to this problem will be outlined and the various steps of a system based on this approach will be described. Steps include the statistical analysis of a collection of documents in a field of interest, the establishment of a set of "notions" and the vocabulary by which they are expressed, the compilation of a thesaurus-type dictionary and index, the automatic encoding of documents by machine with the aid of such a dictionary, the encoding of topological notations (such as branched structures), the recording of the coded information, the establishment of a searching pattern for finding pertinent information, and the programming of appropriate machines to carry out a search.},
journal = {IBM J. Res. Dev.},
month = oct,
pages = {309–317},
numpages = {9}
}
@article{tfidf,
title = "Term-weighting approaches in automatic text retrieval",
journal = "Information Processing \& Management",
volume = "24",
number = "5",
pages = "513 - 523",
year = "1988",
issn = "0306-4573",
doi = "https://doi.org/10.1016/0306-4573(88)90021-0",
url = "http://www.sciencedirect.com/science/article/pii/0306457388900210",
author = "Gerard Salton and Christopher Buckley",
abstract = "The experimental evidence accumulated over the past 20 years indicates that text indexing systems based on the assignment of appropriately weighted single terms produce retrieval results that are superior to those obtainable with other more elaborate text representations. These results depend crucially on the choice of effective termweighting systems. This article summarizes the insights gained in automatic term weighting, and provides baseline single-term-indexing models with which other more elaborate content analysis procedures can be compared."
}
@InProceedings{joachims-svm,
author="Joachims, Thorsten",
editor="N{\'e}dellec, Claire
and Rouveirol, C{\'e}line",
title="Text categorization with Support Vector Machines: Learning with many relevant features",
booktitle="Machine Learning: ECML-98",
year="1998",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="137--142",
abstract="This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning.",
isbn="978-3-540-69781-7"
}
@article{gbacc,
author = {S. Madeh Piryonesi  and Tamer E. El-Diraby },
title = {Role of Data Analytics in Infrastructure Asset Management: Overcoming Data Size and Quality Problems},
journal = {Journal of Transportation Engineering, Part B: Pavements},
volume = {146},
number = {2},
pages = {04020022},
year = {2020},
doi = {10.1061/JPEODX.0000175},

URL = {https://ascelibrary.org/doi/abs/10.1061/JPEODX.0000175 }
}



